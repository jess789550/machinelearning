{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jess789550/machinelearning/blob/main/fcc_predict_health_costs_with_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Health Costs Calculator\n",
        "You will be working on this project with Google Colaboratory.\n",
        "\n",
        "After going to that link, create a copy of the notebook either in your own account or locally. Once you complete the project and it passes the test (included at that link), submit your project link below. If you are submitting a Google Colaboratory link, make sure to turn on link sharing for \"anyone with the link.\"\n",
        "\n",
        "We are still developing the interactive instructional content for the machine learning curriculum. For now, you can go through the video challenges in this certification. You may also have to seek out additional learning resources, similar to what you would do when working on a real-world project.\n",
        "\n",
        "In this challenge, you will predict healthcare costs using a regression algorithm.\n",
        "\n",
        "You are given a dataset that contains information about different people including their healthcare costs. Use the data to predict healthcare costs based on new data.\n",
        "\n",
        "The first two cells of this notebook import libraries and the data.\n",
        "\n",
        "Make sure to convert categorical data to numbers. Use 80% of the data as the train_dataset and 20% of the data as the test_dataset.\n",
        "\n",
        "pop off the \"expenses\" column from these datasets to create new datasets called train_labels and test_labels. Use these labels when training your model.\n",
        "\n",
        "Create a model and train it with the train_dataset. Run the final cell in this notebook to check your model. The final cell will use the unseen test_dataset to check how well the model generalizes.\n",
        "\n",
        "To pass the challenge, model.evaluate must return a Mean Absolute Error of under 3500. This means it predicts health care costs correctly within $3500.\n",
        "\n",
        "The final cell will also predict expenses using the test_dataset and graph the results."
      ],
      "metadata": {
        "id": "EYGW5_qK1sLl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rRo8oNqZ-Rj"
      },
      "outputs": [],
      "source": [
        "# Import libraries. You may or may not use all of these.\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiX2FI4gZtTt"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "!wget https://cdn.freecodecamp.org/project-data/health-costs/insurance.csv\n",
        "dataset = pd.read_csv('insurance.csv')\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcopvQh3X-kX"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/tutorials/keras/regression\n",
        "\n",
        "# Clean data by removing NAs\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "# Split dataset into training and testing\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "# Review the joint distribution of a few pairs of columns from the training set\n",
        "sns.pairplot(train_dataset[['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'expenses']], diag_kind='kde')\n",
        "\n",
        "# Check overall statistics\n",
        "train_dataset.describe().transpose()\n",
        "\n",
        "# Split features from labels\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('expenses')\n",
        "test_labels = test_features.pop('expenses')\n",
        "\n",
        "# Normalisation\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features)) # ERROR\n",
        "print(normalizer.mean.numpy())\n",
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "  print('First example:', first)\n",
        "  print()\n",
        "  print('Normalized:', normalizer(first).numpy())\n",
        "\n",
        "# Linear regression model for expenses\n",
        "expenses = np.array(train_features['expenses'])\n",
        "\n",
        "expenses_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
        "expenses_normalizer.adapt(expenses)\n",
        "\n",
        "expenses_model = tf.keras.Sequential([\n",
        "    expenses_normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "expenses_model.summary()\n",
        "\n",
        "expenses_model.predict(expenses[:10])\n",
        "\n",
        "expenses_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')\n",
        "\n",
        "%%time\n",
        "history = expenses_model.fit(\n",
        "    train_features['expenses'],\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "test_results = {}\n",
        "\n",
        "test_results['expenses_model'] = expenses_model.evaluate(\n",
        "    test_features['expenses'],\n",
        "    test_labels, verbose=0)\n",
        "\n",
        "x = tf.linspace(0.0, 250, 251)\n",
        "y = expenses_model.predict(x)\n",
        "\n",
        "def plot_expenses(x, y):\n",
        "  plt.scatter(train_features['expenses'], train_labels, label='Data')\n",
        "  plt.plot(x, y, color='k', label='Predictions')\n",
        "  plt.xlabel('expenses')\n",
        "  plt.ylabel('age')\n",
        "  plt.legend()\n",
        "\n",
        "plot_expenses(x, y)\n",
        "\n",
        "# Linear regression with multiple inputs\n",
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "linear_model.predict(train_features[:10])\n",
        "\n",
        "linear_model.layers[1].kernel\n",
        "\n",
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')\n",
        "\n",
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "test_results['linear_model'] = linear_model.evaluate(\n",
        "    test_features, test_labels, verbose=0)\n",
        "\n",
        "# Regression with DNN\n",
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model\n",
        "\n",
        "dnn_horsepower_model = build_and_compile_model(expenses_normalizer)\n",
        "\n",
        "dnn_horsepower_model.summary()\n",
        "\n",
        "%%time\n",
        "history = dnn_horsepower_model.fit(\n",
        "    train_features['Horsepower'],\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "x = tf.linspace(0.0, 250, 251)\n",
        "y = dnn_horsepower_model.predict(x)\n",
        "\n",
        "plot_expenses(x, y)\n",
        "\n",
        "test_results['dnn_horsepower_model'] = dnn_horsepower_model.evaluate(\n",
        "    test_features['Horsepower'], test_labels,\n",
        "    verbose=0)\n",
        "\n",
        "dnn_model = build_and_compile_model(normalizer)\n",
        "dnn_model.summary()\n",
        "\n",
        "%%time\n",
        "history = dnn_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepAI\n",
        "\n",
        "# Step 1: Import Libraries\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Step 3: Data Preprocessing\n",
        "# Convert categorical variables to dummy/indicator variables\n",
        "dataset = pd.get_dummies(dataset, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
        "\n",
        "# Split features and target\n",
        "X = dataset.drop('expenses', axis=1)  # Features\n",
        "y = dataset['expenses']  # Target\n",
        "\n",
        "# Split into training and testing datasets (80% train, 20% test)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Building the Model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer\n",
        "    layers.Dense(64, activation='relu'),  # Hidden layer\n",
        "    layers.Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# Step 5: Training the Model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=5, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Step 6: Evaluating the Model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "\n",
        "# Check if the model passes the challenge\n",
        "if mae < 3500:\n",
        "    print(\"Challenge Passed!\")\n",
        "else:\n",
        "    print(\"Challenge Not Passed.\")\n",
        "\n",
        "# Visualizing the performance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Identity line\n",
        "plt.title(\"Actual vs Predicted Expenses\")\n",
        "plt.xlabel(\"Actual Expenses\")\n",
        "plt.ylabel(\"Predicted Expenses\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVr_w6cS7Pze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/parreirahenrique/linear-regression-health-costs-calculator\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Convert categorical data to numbers\n",
        "dataset[\"sex\"].replace(\n",
        "    [\"female\", \"male\"],\n",
        "    [0, 1],\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "dataset[\"smoker\"].replace(\n",
        "    [\"no\", \"yes\"],\n",
        "    [0, 1],\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "dataset[\"region\"].replace(\n",
        "    ['southwest', 'southeast', 'northwest', 'northeast'],\n",
        "    [0, 1, 2, 3],\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "dataset = shuffle(dataset).reset_index(drop=True)\n",
        "\n",
        "# Separating the train and test datasets\n",
        "train_dataset  = dataset[0:int(0.8*dataset.shape[0])]\n",
        "test_dataset = dataset[int(0.8*dataset.shape[0]):dataset.shape[0] - 1]\n",
        "\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "test_labels = test_dataset.pop(\"expenses\")\n",
        "\n",
        "# Creating the model\n",
        "normalizer = layers.experimental.preprocessing.Normalization() # ERROR\n",
        "normalizer.adapt(np.array(train_dataset))\n",
        "\n",
        "model = keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mae',\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "model.build()\n",
        "model.summary()\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    epochs=100\n",
        ")"
      ],
      "metadata": {
        "id": "nNbsFgrwAb5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://letientai.io/freecodecamp/ai/linear_regression/\n",
        "\n",
        "# Text to numeric\n",
        "df = dataset\n",
        "df[\"sex\"] = pd.factorize(df[\"sex\"])[0]\n",
        "df[\"region\"] = pd.factorize(df[\"region\"])[0]\n",
        "df[\"smoker\"] = pd.factorize(df[\"smoker\"])[0]\n",
        "dataset = df\n",
        "dataset.head()\n",
        "\n",
        "# Test dataset\n",
        "test_dataset = dataset.sample(frac=0.2)\n",
        "len(test_dataset)\n",
        "\n",
        "# Training dataset\n",
        "train_dataset = dataset[~dataset.isin(test_dataset)].dropna()\n",
        "len(train_dataset)\n",
        "\n",
        "# Labels\n",
        "train_labels = train_dataset.pop(\"expenses\")\n",
        "train_labels.head()\n",
        "\n",
        "test_labels = test_dataset.pop(\"expenses\")\n",
        "test_labels.head()\n",
        "\n",
        "# Model\n",
        "normalizer = layers.experimental.preprocessing.Normalization() # ERROR\n",
        "normalizer.adapt(np.array(train_dataset))\n",
        "\n",
        "model = keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(16),\n",
        "    layers.Dense(4),\n",
        "    layers.Dropout(.2),\n",
        "    layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mae',\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "model.build()\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    validation_split=0.5,\n",
        "    verbose=0, # disable logging\n",
        ")\n",
        "\n",
        "print(history)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ud0CGJCj-Y9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://colab.research.google.com/drive/1UkEIjC4ngs_1Xv7sXnBB5Ve0kCVm7sSl?usp=sharing#scrollTo=wZEnS_5iK1Mx\n",
        "\n",
        "# Text to numeric\n",
        "prepared_data = dataset.copy()\n",
        "prepared_data['smoker'] = prepared_data['smoker'].map({'no': 0, 'yes': 1})\n",
        "prepared_data['sex'] = prepared_data['sex'].map({'female': 1, 'male': 0})\n",
        "prepared_data = pd.get_dummies(\n",
        "    prepared_data,\n",
        "    columns=['region'],\n",
        "    prefix='',\n",
        "    prefix_sep=''\n",
        ")\n",
        "prepared_data.tail()\n",
        "\n",
        "# Test and train datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tts_data = prepared_data.copy()\n",
        "\n",
        "X = tts_data.drop('expenses', axis=1)\n",
        "y = tts_data.pop('expenses')\n",
        "\n",
        "train_dataset, test_dataset, train_labels, test_labels = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "test_dataset.tail()\n",
        "\n",
        "# Normalisation\n",
        "\n",
        "from tensorflow.keras.layers.experimental import preprocessing # ERROR\n",
        "\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(np.array(train_dataset))\n",
        "\n",
        "# Model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss=['mean_absolute_error'], # Decides about pass the tests from website\n",
        "    metrics=['mean_absolute_error', 'mean_squared_error']  # mse is required in tests from website\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    train_labels,\n",
        "    epochs=50,\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "model.evaluate(\n",
        "    test_dataset,\n",
        "    test_labels,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(\n",
        "    history.history['mean_absolute_error']\n",
        ")\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kfFA8OTBMSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "outputs": [],
      "source": [
        "# RUN THIS CELL TO TEST YOUR MODEL. DO NOT MODIFY CONTENTS.\n",
        "# Test model by checking how well the model generalizes using the test set.\n",
        "loss, mae, mse = model.evaluate(test_dataset, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} expenses\".format(mae))\n",
        "\n",
        "if mae < 3500:\n",
        "  print(\"You passed the challenge. Great job!\")\n",
        "else:\n",
        "  print(\"The Mean Abs Error must be less than 3500. Keep trying.\")\n",
        "\n",
        "# Plot predictions.\n",
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True values (expenses)')\n",
        "plt.ylabel('Predictions (expenses)')\n",
        "lims = [0, 50000]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims,lims)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_predict_health_costs_with_regression.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
